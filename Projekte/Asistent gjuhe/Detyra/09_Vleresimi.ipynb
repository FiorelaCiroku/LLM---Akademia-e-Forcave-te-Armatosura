{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Detyra 9 — Vlerësimi (Evaluation)\n\nQëllimi: të vlerësoni sistemin tuaj kundrejt `qa_benchmark_40.json`.\nMetrika:\n- exact match (për pyetje të thjeshta)\n- refusal accuracy\n- citation presence\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# === Setup (run this cell first) ===\nimport os, json, re, math, random\nfrom pathlib import Path\n\nPROJECT_ROOT = Path(\"/content\")  # In Colab, students will upload the project folder or mount Drive\nDOCS_DIR = PROJECT_ROOT / \"documents\"\nQA_PATH = PROJECT_ROOT / \"qa\" / \"qa_benchmark_40.json\"\n\nprint(\"Docs dir:\", DOCS_DIR)\nprint(\"QA path:\", QA_PATH)\n\n# Tip: If you're using Google Drive:\n# from google.colab import drive\n# drive.mount('/content/drive')\n# PROJECT_ROOT = Path('/content/drive/MyDrive/<YOUR_PROJECT_FOLDER>')\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1) Ngarko benchmark\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import json\nwith open(QA_PATH, \"r\", encoding=\"utf-8\") as f:\n    bench = json.load(f)\nqs = bench[\"questions\"]\nprint(\"Questions:\", len(qs))\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2) Stub system under test\nLidhni këtu funksionin tuaj `answer(query)` nga Week 5 ose agent-in nga Week 7.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def system_answer(query):\n    # TODO: replace with your real system\n    if \"kode emergjente\" in query.lower():\n        return \"Ky informacion nuk gjendet në dokumentin aktual.\"\n    return \"Përgjigje (stub). Citim: (Doc: MIL-ENG-001, unit: 0)\"\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3) Evaluate refusal accuracy\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def is_refusal(q, ans):\n    # very simple heuristic\n    return (\"nuk\" in ans.lower() and \"gjendet\" in ans.lower()) or (\"nuk mund\" in ans.lower())\n\nrefusal_total = 0\nrefusal_correct = 0\n\nfor q in qs:\n    ans = system_answer(q[\"question\"])\n    if q.get(\"must_refuse\"):\n        refusal_total += 1\n        if is_refusal(q[\"question\"], ans):\n            refusal_correct += 1\n\nprint(\"Refusal total:\", refusal_total)\nprint(\"Refusal correct:\", refusal_correct)\nif refusal_total:\n    print(\"Refusal accuracy:\", refusal_correct/refusal_total)\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4) Check citation presence\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def has_citation(ans):\n    return \"Citim\" in ans or \"Doc:\" in ans\n\ncite_total = 0\ncite_ok = 0\nfor q in qs:\n    if q.get(\"must_cite\"):\n        cite_total += 1\n        ans = system_answer(q[\"question\"])\n        if has_citation(ans):\n            cite_ok += 1\nprint(\"Citation required:\", cite_total)\nprint(\"Citation present:\", cite_ok)\nif cite_total:\n    print(\"Citation rate:\", cite_ok/cite_total)\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Dorëzimi\n- Raport me metrika\n- 5 shembuj dështimesh + analiza\n"
    }
  ],
  "metadata": {
    "colab": {
      "name": "09_Vleresimi.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}